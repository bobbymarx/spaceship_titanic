{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fd25144-1a79-4ddf-9e09-be4ce99350d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79baf219-e9f6-408c-b184-219dab298c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"/Users/robertmarks/Desktop/kaggle/spaceship_titanic/input/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "703b92e8-38ab-4b23-878a-a2c2dd03bd59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>B/0/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Maham Ofracculy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Juanna Vines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Altark Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>Solam Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/1/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Willy Santantines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8688</th>\n",
       "      <td>9276_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/98/P</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>41.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6819.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1643.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>Gravior Noxnuther</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8689</th>\n",
       "      <td>9278_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>True</td>\n",
       "      <td>G/1499/S</td>\n",
       "      <td>PSO J318.5-22</td>\n",
       "      <td>18.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Kurta Mondalley</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8690</th>\n",
       "      <td>9279_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>G/1500/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>26.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1872.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Fayey Connon</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8691</th>\n",
       "      <td>9280_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>E/608/S</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>32.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1049.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>353.0</td>\n",
       "      <td>3235.0</td>\n",
       "      <td>Celeon Hontichre</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8692</th>\n",
       "      <td>9280_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>E/608/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>44.0</td>\n",
       "      <td>False</td>\n",
       "      <td>126.0</td>\n",
       "      <td>4688.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Propsh Hontichre</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8693 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId HomePlanet CryoSleep     Cabin    Destination   Age    VIP  \\\n",
       "0        0001_01     Europa     False     B/0/P    TRAPPIST-1e  39.0  False   \n",
       "1        0002_01      Earth     False     F/0/S    TRAPPIST-1e  24.0  False   \n",
       "2        0003_01     Europa     False     A/0/S    TRAPPIST-1e  58.0   True   \n",
       "3        0003_02     Europa     False     A/0/S    TRAPPIST-1e  33.0  False   \n",
       "4        0004_01      Earth     False     F/1/S    TRAPPIST-1e  16.0  False   \n",
       "...          ...        ...       ...       ...            ...   ...    ...   \n",
       "8688     9276_01     Europa     False    A/98/P    55 Cancri e  41.0   True   \n",
       "8689     9278_01      Earth      True  G/1499/S  PSO J318.5-22  18.0  False   \n",
       "8690     9279_01      Earth     False  G/1500/S    TRAPPIST-1e  26.0  False   \n",
       "8691     9280_01     Europa     False   E/608/S    55 Cancri e  32.0  False   \n",
       "8692     9280_02     Europa     False   E/608/S    TRAPPIST-1e  44.0  False   \n",
       "\n",
       "      RoomService  FoodCourt  ShoppingMall     Spa  VRDeck               Name  \\\n",
       "0             0.0        0.0           0.0     0.0     0.0    Maham Ofracculy   \n",
       "1           109.0        9.0          25.0   549.0    44.0       Juanna Vines   \n",
       "2            43.0     3576.0           0.0  6715.0    49.0      Altark Susent   \n",
       "3             0.0     1283.0         371.0  3329.0   193.0       Solam Susent   \n",
       "4           303.0       70.0         151.0   565.0     2.0  Willy Santantines   \n",
       "...           ...        ...           ...     ...     ...                ...   \n",
       "8688          0.0     6819.0           0.0  1643.0    74.0  Gravior Noxnuther   \n",
       "8689          0.0        0.0           0.0     0.0     0.0    Kurta Mondalley   \n",
       "8690          0.0        0.0        1872.0     1.0     0.0       Fayey Connon   \n",
       "8691          0.0     1049.0           0.0   353.0  3235.0   Celeon Hontichre   \n",
       "8692        126.0     4688.0           0.0     0.0    12.0   Propsh Hontichre   \n",
       "\n",
       "      Transported  \n",
       "0           False  \n",
       "1            True  \n",
       "2           False  \n",
       "3           False  \n",
       "4            True  \n",
       "...           ...  \n",
       "8688        False  \n",
       "8689        False  \n",
       "8690         True  \n",
       "8691        False  \n",
       "8692         True  \n",
       "\n",
       "[8693 rows x 14 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31d0952e-ef5b-4d9a-8daf-fccdb6001a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#investigate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f59838cf-9a94-4c21-9fdc-c8c877f3f5ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8514.000000</td>\n",
       "      <td>8512.000000</td>\n",
       "      <td>8510.000000</td>\n",
       "      <td>8485.000000</td>\n",
       "      <td>8510.000000</td>\n",
       "      <td>8505.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>28.827930</td>\n",
       "      <td>224.687617</td>\n",
       "      <td>458.077203</td>\n",
       "      <td>173.729169</td>\n",
       "      <td>311.138778</td>\n",
       "      <td>304.854791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14.489021</td>\n",
       "      <td>666.717663</td>\n",
       "      <td>1611.489240</td>\n",
       "      <td>604.696458</td>\n",
       "      <td>1136.705535</td>\n",
       "      <td>1145.717189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>38.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>46.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>79.000000</td>\n",
       "      <td>14327.000000</td>\n",
       "      <td>29813.000000</td>\n",
       "      <td>23492.000000</td>\n",
       "      <td>22408.000000</td>\n",
       "      <td>24133.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Age   RoomService     FoodCourt  ShoppingMall           Spa  \\\n",
       "count  8514.000000   8512.000000   8510.000000   8485.000000   8510.000000   \n",
       "mean     28.827930    224.687617    458.077203    173.729169    311.138778   \n",
       "std      14.489021    666.717663   1611.489240    604.696458   1136.705535   \n",
       "min       0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%      19.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%      27.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%      38.000000     47.000000     76.000000     27.000000     59.000000   \n",
       "max      79.000000  14327.000000  29813.000000  23492.000000  22408.000000   \n",
       "\n",
       "             VRDeck  \n",
       "count   8505.000000  \n",
       "mean     304.854791  \n",
       "std     1145.717189  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%       46.000000  \n",
       "max    24133.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60454504-926c-491c-8c78-59ed23ec83fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId       0\n",
      "HomePlanet      201\n",
      "CryoSleep       217\n",
      "Cabin           199\n",
      "Destination     182\n",
      "Age             179\n",
      "VIP             203\n",
      "RoomService     181\n",
      "FoodCourt       183\n",
      "ShoppingMall    208\n",
      "Spa             183\n",
      "VRDeck          188\n",
      "Name            200\n",
      "Transported       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "nan_rows = data[data.isna().any(axis=1)]\n",
    "nan_counts = data.isna().sum()\n",
    "\n",
    "print(nan_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c838d9-98bc-4df1-84cb-1cea2ea8022d",
   "metadata": {},
   "source": [
    "To deal with the Nan's let's try to fill them with meaningful things\n",
    "Let's start with the HomePlanet, there are 201 missing; let's check if we can infer some based on the cabin (matching cabin means most probably same start)\n",
    " if not we can also check for last name; if last name is the same as someone elses they probably are related and family is most often close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43f1a593-288e-4501-bc35-9e523bcaf5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#deal with last Name\n",
    "data['Last_Name'] = data['Name'].str.split(' ').str[-1].fillna('Nobody')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94cda6b4-80ba-4bf2-836a-fdab6a302939",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_homeplanet(df):\n",
    "    # Create a copy of the dataframe to avoid modifying the original\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Counter for tracking assignments and remaining NaN values\n",
    "    initial_missing = df['HomePlanet'].isna().sum()\n",
    "    print(f\"Initial number of missing HomePlanet values: {initial_missing}\")\n",
    "    \n",
    "    # Step 1: Fill missing HomePlanet based on Last_Name matches\n",
    "    # First, create a dictionary of known Last_Name to HomePlanet mappings\n",
    "    # (excluding 'Nobody' and NaN values)\n",
    "    known_last_name_mapping = df[\n",
    "        (df['Last_Name'] != 'Nobody') & \n",
    "        (~df['Last_Name'].isna()) & \n",
    "        (~df['HomePlanet'].isna())\n",
    "    ].groupby('Last_Name')['HomePlanet'].first().to_dict()\n",
    "    \n",
    "    # Function to fill HomePlanet based on Last_Name\n",
    "    def fill_by_last_name(row):\n",
    "        if pd.isna(row['HomePlanet']) and not pd.isna(row['Last_Name']):\n",
    "            if row['Last_Name'] != 'Nobody':\n",
    "                return known_last_name_mapping.get(row['Last_Name'])\n",
    "        return row['HomePlanet']\n",
    "    \n",
    "    # Apply the Last_Name based filling\n",
    "    df['HomePlanet'] = df.apply(fill_by_last_name, axis=1)\n",
    "    \n",
    "    # Count how many were filled by Last_Name\n",
    "    after_last_name = df['HomePlanet'].isna().sum()\n",
    "    filled_by_last_name = initial_missing - after_last_name\n",
    "    print(f\"Filled by Last_Name: {filled_by_last_name}\")\n",
    "    \n",
    "    # Step 2: Fill remaining missing HomePlanet based on Cabin matches\n",
    "    # Create a dictionary of known Cabin to HomePlanet mappings\n",
    "    known_cabin_mapping = df[\n",
    "        (~df['Cabin'].isna()) & \n",
    "        (~df['HomePlanet'].isna())\n",
    "    ].groupby('Cabin')['HomePlanet'].first().to_dict()\n",
    "    \n",
    "    # Function to fill HomePlanet based on Cabin\n",
    "    def fill_by_cabin(row):\n",
    "        if pd.isna(row['HomePlanet']) and not pd.isna(row['Cabin']):\n",
    "            return known_cabin_mapping.get(row['Cabin'])\n",
    "        return row['HomePlanet']\n",
    "    \n",
    "    # Apply the Cabin based filling\n",
    "    df['HomePlanet'] = df.apply(fill_by_cabin, axis=1)\n",
    "    \n",
    "    # Count how many were filled by Cabin\n",
    "    final_missing = df['HomePlanet'].isna().sum()\n",
    "    filled_by_cabin = after_last_name - final_missing\n",
    "    print(f\"Filled by Cabin: {filled_by_cabin}\")\n",
    "    print(f\"Remaining missing HomePlanet values: {final_missing}\")\n",
    "    \n",
    "    # Step 3: Fill remaining missing HomePlanet with the most common home planet\n",
    "    if final_missing > 0:\n",
    "        most_common_homeplanet = df['HomePlanet'].mode()[0]\n",
    "        df['HomePlanet'].fillna(most_common_homeplanet, inplace=True)\n",
    "        print(f\"Filled by most common HomePlanet: {final_missing}\")\n",
    "        final_missing = df['HomePlanet'].isna().sum()\n",
    "\n",
    "    print(\"Missing home planets\", final_missing)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c31a37f5-792c-4264-8d18-ae03e6339935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial number of missing HomePlanet values: 201\n",
      "Filled by Last_Name: 186\n",
      "Filled by Cabin: 2\n",
      "Remaining missing HomePlanet values: 13\n",
      "Filled by most common HomePlanet: 13\n",
      "Missing home planets 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gm/ptz_rd3s5fv5m6lks9m633wr0000gn/T/ipykernel_75171/3480501072.py:58: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['HomePlanet'].fillna(most_common_homeplanet, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df= fill_missing_homeplanet(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6189142c-b80b-4e4e-b666-b099bf90abf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_cabin_by_lastname(df):\n",
    "    # Create a dictionary of known LastName to Cabin mappings (excluding \"Nobody\" and NaN values)\n",
    "    known_lastname_mapping = df[\n",
    "        (df['Last_Name'] != 'Nobody') & \n",
    "        (~df['Last_Name'].isna()) & \n",
    "        (~df['Cabin'].isna())\n",
    "    ].groupby('Last_Name')['Cabin'].first().to_dict()\n",
    "    \n",
    "    # Function to fill Cabin based on LastName\n",
    "    def fill_by_lastname(row):\n",
    "        if pd.isna(row['Cabin']) and row['Last_Name'] != 'Nobody':\n",
    "            return known_lastname_mapping.get(row['Last_Name'])\n",
    "        return row['Cabin']\n",
    "    \n",
    "    # Apply the LastName-based filling\n",
    "    df['Cabin'] = df.apply(fill_by_lastname, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "863de436-e3ae-407b-ba03-fff1faec9d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Step 1: Infer Cabin by Last Name\n",
    "df = infer_cabin_by_lastname(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce76ab7f-e678-429e-aa97-d984e0266113",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e4e834-642c-4ece-b404-771a89f705d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "550e3dd9-18f0-477b-9788-90d3c42d48fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's try to replace the cabin\n",
    "# Step 1: Split the Cabin column into cabin_deck, cabin_num, and cabin_side\n",
    "df[['cabin_deck', 'cabin_num', 'cabin_side']] = df['Cabin'].str.split('/', expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "efeb84e0-a501-490b-85d9-65781ee9e4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for people that are in CryoSleep -> if not spent any money in CryoSleep, if spent money on something, not in CryoSleep if one nan leave nan\n",
    "# Define the spending columns\n",
    "# Function to infer CryoSleep\n",
    "def infer_cryosleep(row):\n",
    "    spending_columns = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "    if any(pd.notna(row[col]) and row[col] > 0 for col in spending_columns):  # If any spending > 0\n",
    "        return False\n",
    "    elif all(row[col] == 0 for col in spending_columns):  # If all spending == 0\n",
    "        return True\n",
    "    else:  # If any spending is NaN\n",
    "        nan_count = sum(pd.isna(row[col]) for col in spending_columns)\n",
    "        if nan_count>1:\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "\n",
    "# Apply the function to infer CryoSleep\n",
    "df['CryoSleep'] = df.apply(infer_cryosleep, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "242f0651-3237-482a-a881-1ca77af31e86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId       0\n",
      "HomePlanet        0\n",
      "CryoSleep         0\n",
      "Cabin            11\n",
      "Destination     182\n",
      "Age             179\n",
      "VIP             203\n",
      "RoomService     181\n",
      "FoodCourt       183\n",
      "ShoppingMall    208\n",
      "Spa             183\n",
      "VRDeck          188\n",
      "Name            200\n",
      "Transported       0\n",
      "Last_Name         0\n",
      "cabin_deck       11\n",
      "cabin_num        11\n",
      "cabin_side       11\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "nan_rows = df[df.isna().any(axis=1)]\n",
    "nan_counts = df.isna().sum()\n",
    "\n",
    "print(nan_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "318edfc1-f8c7-4e7c-a704-042e2c78d3e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gm/ptz_rd3s5fv5m6lks9m633wr0000gn/T/ipykernel_75171/2703569800.py:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  distance = np.linalg.norm(row[service_columns].fillna(0) - median_spending.fillna(0))\n",
      "/var/folders/gm/ptz_rd3s5fv5m6lks9m633wr0000gn/T/ipykernel_75171/2703569800.py:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  distance = np.linalg.norm(row[service_columns].fillna(0) - median_spending.fillna(0))\n",
      "/var/folders/gm/ptz_rd3s5fv5m6lks9m633wr0000gn/T/ipykernel_75171/2703569800.py:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  distance = np.linalg.norm(row[service_columns].fillna(0) - median_spending.fillna(0))\n",
      "/var/folders/gm/ptz_rd3s5fv5m6lks9m633wr0000gn/T/ipykernel_75171/2703569800.py:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  distance = np.linalg.norm(row[service_columns].fillna(0) - median_spending.fillna(0))\n",
      "/var/folders/gm/ptz_rd3s5fv5m6lks9m633wr0000gn/T/ipykernel_75171/2703569800.py:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  distance = np.linalg.norm(row[service_columns].fillna(0) - median_spending.fillna(0))\n",
      "/var/folders/gm/ptz_rd3s5fv5m6lks9m633wr0000gn/T/ipykernel_75171/2703569800.py:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  distance = np.linalg.norm(row[service_columns].fillna(0) - median_spending.fillna(0))\n",
      "/var/folders/gm/ptz_rd3s5fv5m6lks9m633wr0000gn/T/ipykernel_75171/2703569800.py:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  distance = np.linalg.norm(row[service_columns].fillna(0) - median_spending.fillna(0))\n",
      "/var/folders/gm/ptz_rd3s5fv5m6lks9m633wr0000gn/T/ipykernel_75171/2703569800.py:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  distance = np.linalg.norm(row[service_columns].fillna(0) - median_spending.fillna(0))\n",
      "/var/folders/gm/ptz_rd3s5fv5m6lks9m633wr0000gn/T/ipykernel_75171/2703569800.py:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  distance = np.linalg.norm(row[service_columns].fillna(0) - median_spending.fillna(0))\n",
      "/var/folders/gm/ptz_rd3s5fv5m6lks9m633wr0000gn/T/ipykernel_75171/2703569800.py:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  distance = np.linalg.norm(row[service_columns].fillna(0) - median_spending.fillna(0))\n",
      "/var/folders/gm/ptz_rd3s5fv5m6lks9m633wr0000gn/T/ipykernel_75171/2703569800.py:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  distance = np.linalg.norm(row[service_columns].fillna(0) - median_spending.fillna(0))\n",
      "/var/folders/gm/ptz_rd3s5fv5m6lks9m633wr0000gn/T/ipykernel_75171/2703569800.py:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  distance = np.linalg.norm(row[service_columns].fillna(0) - median_spending.fillna(0))\n",
      "/var/folders/gm/ptz_rd3s5fv5m6lks9m633wr0000gn/T/ipykernel_75171/2703569800.py:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  distance = np.linalg.norm(row[service_columns].fillna(0) - median_spending.fillna(0))\n",
      "/var/folders/gm/ptz_rd3s5fv5m6lks9m633wr0000gn/T/ipykernel_75171/2703569800.py:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  distance = np.linalg.norm(row[service_columns].fillna(0) - median_spending.fillna(0))\n",
      "/var/folders/gm/ptz_rd3s5fv5m6lks9m633wr0000gn/T/ipykernel_75171/2703569800.py:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  distance = np.linalg.norm(row[service_columns].fillna(0) - median_spending.fillna(0))\n",
      "/var/folders/gm/ptz_rd3s5fv5m6lks9m633wr0000gn/T/ipykernel_75171/2703569800.py:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  distance = np.linalg.norm(row[service_columns].fillna(0) - median_spending.fillna(0))\n",
      "/var/folders/gm/ptz_rd3s5fv5m6lks9m633wr0000gn/T/ipykernel_75171/2703569800.py:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  distance = np.linalg.norm(row[service_columns].fillna(0) - median_spending.fillna(0))\n",
      "/var/folders/gm/ptz_rd3s5fv5m6lks9m633wr0000gn/T/ipykernel_75171/2703569800.py:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  distance = np.linalg.norm(row[service_columns].fillna(0) - median_spending.fillna(0))\n",
      "/var/folders/gm/ptz_rd3s5fv5m6lks9m633wr0000gn/T/ipykernel_75171/2703569800.py:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  distance = np.linalg.norm(row[service_columns].fillna(0) - median_spending.fillna(0))\n",
      "/var/folders/gm/ptz_rd3s5fv5m6lks9m633wr0000gn/T/ipykernel_75171/2703569800.py:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  distance = np.linalg.norm(row[service_columns].fillna(0) - median_spending.fillna(0))\n",
      "/var/folders/gm/ptz_rd3s5fv5m6lks9m633wr0000gn/T/ipykernel_75171/2703569800.py:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  distance = np.linalg.norm(row[service_columns].fillna(0) - median_spending.fillna(0))\n",
      "/var/folders/gm/ptz_rd3s5fv5m6lks9m633wr0000gn/T/ipykernel_75171/2703569800.py:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  distance = np.linalg.norm(row[service_columns].fillna(0) - median_spending.fillna(0))\n",
      "/var/folders/gm/ptz_rd3s5fv5m6lks9m633wr0000gn/T/ipykernel_75171/2703569800.py:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  distance = np.linalg.norm(row[service_columns].fillna(0) - median_spending.fillna(0))\n",
      "/var/folders/gm/ptz_rd3s5fv5m6lks9m633wr0000gn/T/ipykernel_75171/2703569800.py:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  distance = np.linalg.norm(row[service_columns].fillna(0) - median_spending.fillna(0))\n",
      "/var/folders/gm/ptz_rd3s5fv5m6lks9m633wr0000gn/T/ipykernel_75171/2703569800.py:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  distance = np.linalg.norm(row[service_columns].fillna(0) - median_spending.fillna(0))\n",
      "/var/folders/gm/ptz_rd3s5fv5m6lks9m633wr0000gn/T/ipykernel_75171/2703569800.py:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  distance = np.linalg.norm(row[service_columns].fillna(0) - median_spending.fillna(0))\n",
      "/var/folders/gm/ptz_rd3s5fv5m6lks9m633wr0000gn/T/ipykernel_75171/2703569800.py:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  distance = np.linalg.norm(row[service_columns].fillna(0) - median_spending.fillna(0))\n",
      "/var/folders/gm/ptz_rd3s5fv5m6lks9m633wr0000gn/T/ipykernel_75171/2703569800.py:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  distance = np.linalg.norm(row[service_columns].fillna(0) - median_spending.fillna(0))\n",
      "/var/folders/gm/ptz_rd3s5fv5m6lks9m633wr0000gn/T/ipykernel_75171/2703569800.py:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  distance = np.linalg.norm(row[service_columns].fillna(0) - median_spending.fillna(0))\n",
      "/var/folders/gm/ptz_rd3s5fv5m6lks9m633wr0000gn/T/ipykernel_75171/2703569800.py:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  distance = np.linalg.norm(row[service_columns].fillna(0) - median_spending.fillna(0))\n",
      "/var/folders/gm/ptz_rd3s5fv5m6lks9m633wr0000gn/T/ipykernel_75171/2703569800.py:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  distance = np.linalg.norm(row[service_columns].fillna(0) - median_spending.fillna(0))\n",
      "/var/folders/gm/ptz_rd3s5fv5m6lks9m633wr0000gn/T/ipykernel_75171/2703569800.py:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  distance = np.linalg.norm(row[service_columns].fillna(0) - median_spending.fillna(0))\n",
      "/var/folders/gm/ptz_rd3s5fv5m6lks9m633wr0000gn/T/ipykernel_75171/2703569800.py:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  distance = np.linalg.norm(row[service_columns].fillna(0) - median_spending.fillna(0))\n",
      "/var/folders/gm/ptz_rd3s5fv5m6lks9m633wr0000gn/T/ipykernel_75171/2703569800.py:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  distance = np.linalg.norm(row[service_columns].fillna(0) - median_spending.fillna(0))\n",
      "/var/folders/gm/ptz_rd3s5fv5m6lks9m633wr0000gn/T/ipykernel_75171/2703569800.py:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  distance = np.linalg.norm(row[service_columns].fillna(0) - median_spending.fillna(0))\n",
      "/var/folders/gm/ptz_rd3s5fv5m6lks9m633wr0000gn/T/ipykernel_75171/2703569800.py:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  distance = np.linalg.norm(row[service_columns].fillna(0) - median_spending.fillna(0))\n",
      "/var/folders/gm/ptz_rd3s5fv5m6lks9m633wr0000gn/T/ipykernel_75171/2703569800.py:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  distance = np.linalg.norm(row[service_columns].fillna(0) - median_spending.fillna(0))\n",
      "/var/folders/gm/ptz_rd3s5fv5m6lks9m633wr0000gn/T/ipykernel_75171/2703569800.py:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  distance = np.linalg.norm(row[service_columns].fillna(0) - median_spending.fillna(0))\n",
      "/var/folders/gm/ptz_rd3s5fv5m6lks9m633wr0000gn/T/ipykernel_75171/2703569800.py:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  distance = np.linalg.norm(row[service_columns].fillna(0) - median_spending.fillna(0))\n",
      "/var/folders/gm/ptz_rd3s5fv5m6lks9m633wr0000gn/T/ipykernel_75171/2703569800.py:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  distance = np.linalg.norm(row[service_columns].fillna(0) - median_spending.fillna(0))\n",
      "/var/folders/gm/ptz_rd3s5fv5m6lks9m633wr0000gn/T/ipykernel_75171/2703569800.py:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  distance = np.linalg.norm(row[service_columns].fillna(0) - median_spending.fillna(0))\n",
      "/var/folders/gm/ptz_rd3s5fv5m6lks9m633wr0000gn/T/ipykernel_75171/2703569800.py:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  distance = np.linalg.norm(row[service_columns].fillna(0) - median_spending.fillna(0))\n",
      "/var/folders/gm/ptz_rd3s5fv5m6lks9m633wr0000gn/T/ipykernel_75171/2703569800.py:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  distance = np.linalg.norm(row[service_columns].fillna(0) - median_spending.fillna(0))\n",
      "/var/folders/gm/ptz_rd3s5fv5m6lks9m633wr0000gn/T/ipykernel_75171/2703569800.py:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  distance = np.linalg.norm(row[service_columns].fillna(0) - median_spending.fillna(0))\n",
      "/var/folders/gm/ptz_rd3s5fv5m6lks9m633wr0000gn/T/ipykernel_75171/2703569800.py:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  distance = np.linalg.norm(row[service_columns].fillna(0) - median_spending.fillna(0))\n",
      "/var/folders/gm/ptz_rd3s5fv5m6lks9m633wr0000gn/T/ipykernel_75171/2703569800.py:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  distance = np.linalg.norm(row[service_columns].fillna(0) - median_spending.fillna(0))\n",
      "/var/folders/gm/ptz_rd3s5fv5m6lks9m633wr0000gn/T/ipykernel_75171/2703569800.py:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  distance = np.linalg.norm(row[service_columns].fillna(0) - median_spending.fillna(0))\n",
      "/var/folders/gm/ptz_rd3s5fv5m6lks9m633wr0000gn/T/ipykernel_75171/2703569800.py:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  distance = np.linalg.norm(row[service_columns].fillna(0) - median_spending.fillna(0))\n",
      "/var/folders/gm/ptz_rd3s5fv5m6lks9m633wr0000gn/T/ipykernel_75171/2703569800.py:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  distance = np.linalg.norm(row[service_columns].fillna(0) - median_spending.fillna(0))\n",
      "/var/folders/gm/ptz_rd3s5fv5m6lks9m633wr0000gn/T/ipykernel_75171/2703569800.py:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  distance = np.linalg.norm(row[service_columns].fillna(0) - median_spending.fillna(0))\n",
      "/var/folders/gm/ptz_rd3s5fv5m6lks9m633wr0000gn/T/ipykernel_75171/2703569800.py:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  distance = np.linalg.norm(row[service_columns].fillna(0) - median_spending.fillna(0))\n",
      "/var/folders/gm/ptz_rd3s5fv5m6lks9m633wr0000gn/T/ipykernel_75171/2703569800.py:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  distance = np.linalg.norm(row[service_columns].fillna(0) - median_spending.fillna(0))\n",
      "/var/folders/gm/ptz_rd3s5fv5m6lks9m633wr0000gn/T/ipykernel_75171/2703569800.py:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  distance = np.linalg.norm(row[service_columns].fillna(0) - median_spending.fillna(0))\n",
      "/var/folders/gm/ptz_rd3s5fv5m6lks9m633wr0000gn/T/ipykernel_75171/2703569800.py:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  distance = np.linalg.norm(row[service_columns].fillna(0) - median_spending.fillna(0))\n",
      "/var/folders/gm/ptz_rd3s5fv5m6lks9m633wr0000gn/T/ipykernel_75171/2703569800.py:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  distance = np.linalg.norm(row[service_columns].fillna(0) - median_spending.fillna(0))\n",
      "/var/folders/gm/ptz_rd3s5fv5m6lks9m633wr0000gn/T/ipykernel_75171/2703569800.py:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  distance = np.linalg.norm(row[service_columns].fillna(0) - median_spending.fillna(0))\n",
      "/var/folders/gm/ptz_rd3s5fv5m6lks9m633wr0000gn/T/ipykernel_75171/2703569800.py:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  distance = np.linalg.norm(row[service_columns].fillna(0) - median_spending.fillna(0))\n",
      "/var/folders/gm/ptz_rd3s5fv5m6lks9m633wr0000gn/T/ipykernel_75171/2703569800.py:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  distance = np.linalg.norm(row[service_columns].fillna(0) - median_spending.fillna(0))\n",
      "/var/folders/gm/ptz_rd3s5fv5m6lks9m633wr0000gn/T/ipykernel_75171/2703569800.py:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  distance = np.linalg.norm(row[service_columns].fillna(0) - median_spending.fillna(0))\n",
      "/var/folders/gm/ptz_rd3s5fv5m6lks9m633wr0000gn/T/ipykernel_75171/2703569800.py:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  distance = np.linalg.norm(row[service_columns].fillna(0) - median_spending.fillna(0))\n",
      "/var/folders/gm/ptz_rd3s5fv5m6lks9m633wr0000gn/T/ipykernel_75171/2703569800.py:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  distance = np.linalg.norm(row[service_columns].fillna(0) - median_spending.fillna(0))\n",
      "/var/folders/gm/ptz_rd3s5fv5m6lks9m633wr0000gn/T/ipykernel_75171/2703569800.py:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  distance = np.linalg.norm(row[service_columns].fillna(0) - median_spending.fillna(0))\n",
      "/var/folders/gm/ptz_rd3s5fv5m6lks9m633wr0000gn/T/ipykernel_75171/2703569800.py:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  distance = np.linalg.norm(row[service_columns].fillna(0) - median_spending.fillna(0))\n",
      "/var/folders/gm/ptz_rd3s5fv5m6lks9m633wr0000gn/T/ipykernel_75171/2703569800.py:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  distance = np.linalg.norm(row[service_columns].fillna(0) - median_spending.fillna(0))\n",
      "/var/folders/gm/ptz_rd3s5fv5m6lks9m633wr0000gn/T/ipykernel_75171/2703569800.py:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  distance = np.linalg.norm(row[service_columns].fillna(0) - median_spending.fillna(0))\n",
      "/var/folders/gm/ptz_rd3s5fv5m6lks9m633wr0000gn/T/ipykernel_75171/2703569800.py:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  distance = np.linalg.norm(row[service_columns].fillna(0) - median_spending.fillna(0))\n",
      "/var/folders/gm/ptz_rd3s5fv5m6lks9m633wr0000gn/T/ipykernel_75171/2703569800.py:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  distance = np.linalg.norm(row[service_columns].fillna(0) - median_spending.fillna(0))\n",
      "/var/folders/gm/ptz_rd3s5fv5m6lks9m633wr0000gn/T/ipykernel_75171/2703569800.py:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  distance = np.linalg.norm(row[service_columns].fillna(0) - median_spending.fillna(0))\n",
      "/var/folders/gm/ptz_rd3s5fv5m6lks9m633wr0000gn/T/ipykernel_75171/2703569800.py:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  distance = np.linalg.norm(row[service_columns].fillna(0) - median_spending.fillna(0))\n",
      "/var/folders/gm/ptz_rd3s5fv5m6lks9m633wr0000gn/T/ipykernel_75171/2703569800.py:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  distance = np.linalg.norm(row[service_columns].fillna(0) - median_spending.fillna(0))\n",
      "/var/folders/gm/ptz_rd3s5fv5m6lks9m633wr0000gn/T/ipykernel_75171/2703569800.py:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  distance = np.linalg.norm(row[service_columns].fillna(0) - median_spending.fillna(0))\n",
      "/var/folders/gm/ptz_rd3s5fv5m6lks9m633wr0000gn/T/ipykernel_75171/2703569800.py:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  distance = np.linalg.norm(row[service_columns].fillna(0) - median_spending.fillna(0))\n",
      "/var/folders/gm/ptz_rd3s5fv5m6lks9m633wr0000gn/T/ipykernel_75171/2703569800.py:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  distance = np.linalg.norm(row[service_columns].fillna(0) - median_spending.fillna(0))\n",
      "/var/folders/gm/ptz_rd3s5fv5m6lks9m633wr0000gn/T/ipykernel_75171/2703569800.py:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  distance = np.linalg.norm(row[service_columns].fillna(0) - median_spending.fillna(0))\n",
      "/var/folders/gm/ptz_rd3s5fv5m6lks9m633wr0000gn/T/ipykernel_75171/2703569800.py:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  distance = np.linalg.norm(row[service_columns].fillna(0) - median_spending.fillna(0))\n",
      "/var/folders/gm/ptz_rd3s5fv5m6lks9m633wr0000gn/T/ipykernel_75171/2703569800.py:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  distance = np.linalg.norm(row[service_columns].fillna(0) - median_spending.fillna(0))\n",
      "/var/folders/gm/ptz_rd3s5fv5m6lks9m633wr0000gn/T/ipykernel_75171/2703569800.py:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  distance = np.linalg.norm(row[service_columns].fillna(0) - median_spending.fillna(0))\n",
      "/var/folders/gm/ptz_rd3s5fv5m6lks9m633wr0000gn/T/ipykernel_75171/2703569800.py:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  distance = np.linalg.norm(row[service_columns].fillna(0) - median_spending.fillna(0))\n",
      "/var/folders/gm/ptz_rd3s5fv5m6lks9m633wr0000gn/T/ipykernel_75171/2703569800.py:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  distance = np.linalg.norm(row[service_columns].fillna(0) - median_spending.fillna(0))\n",
      "/var/folders/gm/ptz_rd3s5fv5m6lks9m633wr0000gn/T/ipykernel_75171/2703569800.py:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  distance = np.linalg.norm(row[service_columns].fillna(0) - median_spending.fillna(0))\n",
      "/var/folders/gm/ptz_rd3s5fv5m6lks9m633wr0000gn/T/ipykernel_75171/2703569800.py:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  distance = np.linalg.norm(row[service_columns].fillna(0) - median_spending.fillna(0))\n",
      "/var/folders/gm/ptz_rd3s5fv5m6lks9m633wr0000gn/T/ipykernel_75171/2703569800.py:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  distance = np.linalg.norm(row[service_columns].fillna(0) - median_spending.fillna(0))\n",
      "/var/folders/gm/ptz_rd3s5fv5m6lks9m633wr0000gn/T/ipykernel_75171/2703569800.py:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  distance = np.linalg.norm(row[service_columns].fillna(0) - median_spending.fillna(0))\n",
      "/var/folders/gm/ptz_rd3s5fv5m6lks9m633wr0000gn/T/ipykernel_75171/2703569800.py:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  distance = np.linalg.norm(row[service_columns].fillna(0) - median_spending.fillna(0))\n",
      "/var/folders/gm/ptz_rd3s5fv5m6lks9m633wr0000gn/T/ipykernel_75171/2703569800.py:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  distance = np.linalg.norm(row[service_columns].fillna(0) - median_spending.fillna(0))\n",
      "/var/folders/gm/ptz_rd3s5fv5m6lks9m633wr0000gn/T/ipykernel_75171/2703569800.py:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  distance = np.linalg.norm(row[service_columns].fillna(0) - median_spending.fillna(0))\n",
      "/var/folders/gm/ptz_rd3s5fv5m6lks9m633wr0000gn/T/ipykernel_75171/2703569800.py:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  distance = np.linalg.norm(row[service_columns].fillna(0) - median_spending.fillna(0))\n",
      "/var/folders/gm/ptz_rd3s5fv5m6lks9m633wr0000gn/T/ipykernel_75171/2703569800.py:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  distance = np.linalg.norm(row[service_columns].fillna(0) - median_spending.fillna(0))\n"
     ]
    }
   ],
   "source": [
    "# Define the service columns\n",
    "service_columns = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "\n",
    "# Step 3: Infer Cabin Deck from Spending Patterns\n",
    "def infer_cabin_deck_from_spending(df):\n",
    "    # Calculate the median spending for each cabin deck\n",
    "    median_spending_by_deck = df.groupby('cabin_deck')[service_columns].median()\n",
    "    \n",
    "    # Function to find the most similar deck based on spending\n",
    "    def find_most_similar_deck(row):\n",
    "        if pd.isna(row['cabin_deck']):\n",
    "            # Calculate the Euclidean distance between the passenger's spending and the median spending of each deck\n",
    "            distances = {}\n",
    "            for deck, median_spending in median_spending_by_deck.iterrows():\n",
    "                distance = np.linalg.norm(row[service_columns].fillna(0) - median_spending.fillna(0))\n",
    "                distances[deck] = distance\n",
    "            # Assign the deck with the smallest distance\n",
    "            return min(distances, key=distances.get)\n",
    "        return row['cabin_deck']\n",
    "    \n",
    "    # Apply the spending-based filling\n",
    "    df['cabin_deck'] = df.apply(find_most_similar_deck, axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "# Infer Cabin Deck from Spending Patterns\n",
    "df = infer_cabin_deck_from_spending(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fd7beb18-e869-4cb1-8247-824d0b9ca2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assign random number to cabin's depending on the distribution of the deck; \n",
    "def assign_random_cabin_num(df):\n",
    "    # Ensure cabin_num is numeric\n",
    "    df['cabin_num'] = pd.to_numeric(df['cabin_num'], errors='coerce')\n",
    "    \n",
    "    # Group by cabin_deck and calculate the min and max cabin_num for each deck\n",
    "    deck_stats = df.groupby('cabin_deck')['cabin_num'].agg(['min', 'max']).reset_index()\n",
    "    \n",
    "    # Merge the stats back into the original DataFrame\n",
    "    df = df.merge(deck_stats, on='cabin_deck', how='left')\n",
    "    \n",
    "    # Assign a random cabin number within the range of the deck\n",
    "    def random_cabin_num(row):\n",
    "        if pd.isna(row['cabin_num']):  # Only fill missing cabin_num\n",
    "            return np.random.randint(row['min'], row['max'] + 1)\n",
    "        return row['cabin_num']\n",
    "    \n",
    "    df['cabin_num'] = df.apply(random_cabin_num, axis=1)\n",
    "    \n",
    "    # Drop the temporary min and max columns\n",
    "    df = df.drop(columns=['min', 'max'])\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f8d28219-4332-4580-8d8b-5549298a09f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign minority side to the cabin depending on the level, so that the cabin's are equally distributed on a level\n",
    "def assign_minority_side(df):\n",
    "    # Group by cabin_deck and cabin_side to count the number of cabins on each side\n",
    "    side_counts = df.groupby(['cabin_deck', 'cabin_side']).size().unstack(fill_value=0)\n",
    "    \n",
    "    # Function to assign the minority side for a given deck\n",
    "    def get_minority_side(deck):\n",
    "        if deck not in side_counts.index:\n",
    "            return np.random.choice(['S', 'P'])  # If deck is new, randomly assign a side\n",
    "        return 'S' if side_counts.loc[deck, 'S'] < side_counts.loc[deck, 'P'] else 'P'\n",
    "    \n",
    "    # Assign the minority side to cabins with missing cabin_side\n",
    "    df['cabin_side'] = df.apply(\n",
    "        lambda row: get_minority_side(row['cabin_deck']) if pd.isna(row['cabin_side']) else row['cabin_side'],\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ca692595-fd55-497a-9546-b8e4b0280482",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Apply Function 1: Assign random cabin numbers based on deck distribution\n",
    "df = assign_random_cabin_num(df)\n",
    "\n",
    "# Apply Function 2: Assign minority side to ensure equal distribution\n",
    "df = assign_minority_side(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dd0785df-eafd-4edd-8a6b-049cf93cb357",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's investigate the missing spendings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f6891ebc-3797-409a-a7b8-e20a6c8e371f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of Missing Values per Passenger:\n",
      "missing_count\n",
      "0    7785\n",
      "1     873\n",
      "2      35\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Passengers Missing All Services:\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Define the service columns\n",
    "service_columns = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "\n",
    "# Step 1: Identify passengers with missing spending values\n",
    "df['missing_count'] = df[service_columns].isna().sum(axis=1)\n",
    "\n",
    "# Step 2: Count how many passengers have missing values for each number of services\n",
    "missing_distribution = df['missing_count'].value_counts().sort_index()\n",
    "\n",
    "# Step 3: Analyze the distribution of missing values\n",
    "print(\"Distribution of Missing Values per Passenger:\")\n",
    "print(missing_distribution)\n",
    "\n",
    "# Step 4: Identify passengers missing all services\n",
    "passengers_missing_all = df[df['missing_count'] == len(service_columns)]['PassengerId']\n",
    "print(\"\\nPassengers Missing All Services:\")\n",
    "print(passengers_missing_all.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "51ea9b55-b6d4-4094-a4a0-1c7fc684fd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's deal with the spendings\n",
    "#1st let's follow our argumentation/ intuition from above -> if someone is in CryoSleep, they don't spent any money\n",
    "df.loc[df['CryoSleep'] == True, service_columns] = df.loc[df['CryoSleep'] == True, service_columns].fillna(0)\n",
    "#2rd let's infer the missing values if only one is missing -> impute a randomNumber between the highest and lowest spending of this person of the other services\n",
    "def impute_single_missing_spending(row):\n",
    "    # Count the number of missing values in service_columns\n",
    "    missing_count = row[service_columns].isna().sum()\n",
    "    \n",
    "    # If only one service is missing, impute a random value between the lowest and highest spending of other services\n",
    "    if missing_count == 1:\n",
    "        # Get the non-missing spending values\n",
    "        non_missing_spendings = row[service_columns].dropna()\n",
    "        \n",
    "        # Calculate the range for imputation\n",
    "        min_spending = non_missing_spendings.min()\n",
    "        max_spending = non_missing_spendings.max()\n",
    "        \n",
    "        # Impute a random value between min and max\n",
    "        for service in service_columns:\n",
    "            if pd.isna(row[service]):\n",
    "                row[service] = np.random.uniform(min_spending, max_spending)\n",
    "    \n",
    "    return row\n",
    "\n",
    "df = df.apply(impute_single_missing_spending, axis=1)\n",
    "#3rd if they have more than one missing, Group by relevant columns and calculate the median spending for each service\n",
    "group_stats = df.groupby(['HomePlanet', 'Destination', 'cabin_deck'])[service_columns].median()\n",
    "\n",
    "# Fill missing values based on group statistics\n",
    "for service in service_columns:\n",
    "    df[service] = df.apply(\n",
    "        lambda row: group_stats.loc[(row['HomePlanet'], row['Destination'], row['cabin_deck']), service] \n",
    "        if pd.isna(row[service]) else row[service],\n",
    "        axis=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da5d765-d515-4458-94cf-f9185410d918",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "248fe4a7-bea8-450d-81f0-9bf1b3540017",
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's deal with destination\n",
    "# Define the unique destinations and home planets\n",
    "destinations = ['TRAPPIST-1e', 'PSO J318.5-22', '55 Cancri e']\n",
    "home_planets = ['Europa', 'Earth', 'Mars']\n",
    "\n",
    "# Step 1: Infer Destination based on Last_Name\n",
    "def infer_destination_by_lastname(df):\n",
    "    # Create a dictionary of known Last_Name to Destination mappings (excluding \"Nobody\" and NaN values)\n",
    "    known_lastname_mapping = df[\n",
    "        (df['Last_Name'] != 'Nobody') & \n",
    "        (~df['Last_Name'].isna()) & \n",
    "        (~df['Destination'].isna())\n",
    "    ].groupby('Last_Name')['Destination'].first().to_dict()\n",
    "    \n",
    "    # Function to fill Destination based on Last_Name\n",
    "    def fill_by_lastname(row):\n",
    "        if pd.isna(row['Destination']) and row['Last_Name'] != 'Nobody':\n",
    "            return known_lastname_mapping.get(row['Last_Name'])\n",
    "        return row['Destination']\n",
    "    \n",
    "    # Apply the Last_Name-based filling\n",
    "    df['Destination'] = df.apply(fill_by_lastname, axis=1)\n",
    "    return df\n",
    "\n",
    "# Step 2: Infer Destination based on Home Planet probabilities\n",
    "def infer_destination_by_homeplanet(df):\n",
    "    # Calculate the probability distribution of Destination for each HomePlanet\n",
    "    destination_prob = df.groupby('HomePlanet')['Destination'].value_counts(normalize=True).unstack()\n",
    "    \n",
    "    # Function to fill Destination based on HomePlanet probabilities\n",
    "    def fill_by_homeplanet(row):\n",
    "        if pd.isna(row['Destination']):\n",
    "            probabilities = destination_prob.loc[row['HomePlanet']]\n",
    "            return np.random.choice(probabilities.index, p=probabilities.values)\n",
    "        return row['Destination']\n",
    "    \n",
    "    # Apply the HomePlanet-based filling\n",
    "    df['Destination'] = df.apply(fill_by_homeplanet, axis=1)\n",
    "    return df\n",
    "\n",
    "# Apply Step 1: Infer Destination by Last_Name\n",
    "df = infer_destination_by_lastname(df)\n",
    "\n",
    "# Apply Step 2: Infer Destination by HomePlanet probabilities\n",
    "df = infer_destination_by_homeplanet(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef86e4f-5a04-4efa-8274-ec1671cc38f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1fa8ae66-d81a-4651-9a5f-0f02ea3c4f22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Spending for VIP Passengers:\n",
      "RoomService      482.052335\n",
      "FoodCourt       1770.785551\n",
      "ShoppingMall     265.240717\n",
      "Spa              761.700518\n",
      "VRDeck          1219.889440\n",
      "dtype: float64\n",
      "\n",
      "Median Spending for VIP Passengers:\n",
      "RoomService       0.000000\n",
      "FoodCourt       290.283552\n",
      "ShoppingMall      0.000000\n",
      "Spa              39.000000\n",
      "VRDeck           31.000000\n",
      "dtype: float64\n",
      "\n",
      "Mean Spending for Non-VIP Passengers:\n",
      "RoomService     222.780762\n",
      "FoodCourt       425.474758\n",
      "ShoppingMall    179.280753\n",
      "Spa             303.361698\n",
      "VRDeck          282.690736\n",
      "dtype: float64\n",
      "\n",
      "Median Spending for Non-VIP Passengers:\n",
      "RoomService     0.0\n",
      "FoodCourt       0.0\n",
      "ShoppingMall    0.0\n",
      "Spa             0.0\n",
      "VRDeck          0.0\n",
      "dtype: float64\n",
      "\n",
      "Mean Total Spending for VIP Passengers:\n",
      "4499.668560502835\n",
      "\n",
      "Median Total Spending for VIP Passengers:\n",
      "2785.0\n",
      "\n",
      "Mean Total Spending for Non-VIP Passengers:\n",
      "1413.588706725356\n",
      "\n",
      "Median Total Spending for Non-VIP Passengers:\n",
      "716.0\n"
     ]
    }
   ],
   "source": [
    "# Define the service columns\n",
    "service_columns = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "\n",
    "# Step 1: Compare mean and median spending for VIP and non-VIP passengers\n",
    "vip_spending = df[df['VIP'] == True][service_columns]\n",
    "non_vip_spending = df[df['VIP'] == False][service_columns]\n",
    "\n",
    "# Calculate mean and median spending for VIP and non-VIP passengers\n",
    "vip_mean = vip_spending.mean()\n",
    "vip_median = vip_spending.median()\n",
    "non_vip_mean = non_vip_spending.mean()\n",
    "non_vip_median = non_vip_spending.median()\n",
    "\n",
    "print(\"Mean Spending for VIP Passengers:\")\n",
    "print(vip_mean)\n",
    "print(\"\\nMedian Spending for VIP Passengers:\")\n",
    "print(vip_median)\n",
    "\n",
    "print(\"\\nMean Spending for Non-VIP Passengers:\")\n",
    "print(non_vip_mean)\n",
    "print(\"\\nMedian Spending for Non-VIP Passengers:\")\n",
    "print(non_vip_median)\n",
    "\n",
    "# Step 2: Compare overall spending (sum of all services) for VIP and non-VIP passengers\n",
    "df['total_spending'] = df[service_columns].sum(axis=1)\n",
    "\n",
    "vip_total_spending = df[df['VIP'] == True]['total_spending']\n",
    "non_vip_total_spending = df[df['VIP'] == False]['total_spending']\n",
    "\n",
    "# Calculate mean and median total spending for VIP and non-VIP passengers\n",
    "vip_total_mean = vip_total_spending.mean()\n",
    "vip_total_median = vip_total_spending.median()\n",
    "non_vip_total_mean = non_vip_total_spending.mean()\n",
    "non_vip_total_median = non_vip_total_spending.median()\n",
    "\n",
    "print(\"\\nMean Total Spending for VIP Passengers:\")\n",
    "print(vip_total_mean)\n",
    "print(\"\\nMedian Total Spending for VIP Passengers:\")\n",
    "print(vip_total_median)\n",
    "\n",
    "print(\"\\nMean Total Spending for Non-VIP Passengers:\")\n",
    "print(non_vip_total_mean)\n",
    "print(\"\\nMedian Total Spending for Non-VIP Passengers:\")\n",
    "print(non_vip_total_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "714c77e9-c796-48f9-8686-14e8ef099ed4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gm/ptz_rd3s5fv5m6lks9m633wr0000gn/T/ipykernel_75171/2007379956.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['VIP'] = pipeline.predict(X_test)\n"
     ]
    }
   ],
   "source": [
    "#Infer VIP Status from KNN\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Define the service columns and features\n",
    "service_columns = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "features = ['cabin_deck'] + service_columns\n",
    "\n",
    "# Separate the data into training and test sets\n",
    "train_df = df[df['VIP'].notna()]  # Rows with known VIP status\n",
    "test_df = df[df['VIP'].isna()]    # Rows with missing VIP status\n",
    "\n",
    "# Prepare the features and target\n",
    "X_train = train_df[features]\n",
    "y_train = train_df['VIP']\n",
    "X_test = test_df[features]\n",
    "\n",
    "# Preprocessing pipeline\n",
    "# One-hot encode 'cabin_deck' and scale numerical features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(), ['cabin_deck']),  # One-hot encode 'cabin_deck'\n",
    "        ('num', StandardScaler(), service_columns)  # Scale spending columns\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create a pipeline with preprocessing and KNN classifier\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', KNeighborsClassifier(n_neighbors=3))  # Use 3 nearest neighbors\n",
    "])\n",
    "\n",
    "y_train = y_train.astype('category')  # Ensure categorical dtype\n",
    "\n",
    "# Train the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict missing VIP labels\n",
    "test_df['VIP'] = pipeline.predict(X_test)\n",
    "\n",
    "# Update the original DataFrame with the predicted VIP labels\n",
    "df.loc[test_df.index, 'VIP'] = test_df['VIP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0a19a5e3-114c-47da-bbbc-33134b281389",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's impute the missing ages \"simply\" with the median value\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(strategy='median')  # Use median for imputation\n",
    "df[['Age']] = imputer.fit_transform(df[['Age']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e780822a-28a1-44e7-8efa-d67c7ae6286b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId         0\n",
      "HomePlanet          0\n",
      "CryoSleep           0\n",
      "Cabin              11\n",
      "Destination         0\n",
      "Age                 0\n",
      "VIP                 0\n",
      "RoomService         0\n",
      "FoodCourt           0\n",
      "ShoppingMall        0\n",
      "Spa                 0\n",
      "VRDeck              0\n",
      "Name              200\n",
      "Transported         0\n",
      "Last_Name           0\n",
      "cabin_deck          0\n",
      "cabin_num           0\n",
      "cabin_side          0\n",
      "missing_count       0\n",
      "total_spending      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "nan_rows = df[df.isna().any(axis=1)]\n",
    "nan_counts = df.isna().sum()\n",
    "\n",
    "print(nan_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5dfc64db-ba07-4a1d-aed1-0ffcc74019da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature engineering!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "68fa99b0-9a72-4c3a-9531-5cbc06669f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's add a column for has spent money and family and family_size\n",
    "df['money_spent']=df['total_spending']>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fec01fc6-893a-497d-bbc7-829e4b26652b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PassengerId HomePlanet  CryoSleep     Cabin    Destination   Age    VIP  \\\n",
      "0        0001_01     Europa       True     B/0/P    TRAPPIST-1e  39.0  False   \n",
      "1        0002_01      Earth      False     F/0/S    TRAPPIST-1e  24.0  False   \n",
      "2        0003_01     Europa      False     A/0/S    TRAPPIST-1e  58.0   True   \n",
      "3        0003_02     Europa      False     A/0/S    TRAPPIST-1e  33.0  False   \n",
      "4        0004_01      Earth      False     F/1/S    TRAPPIST-1e  16.0  False   \n",
      "...          ...        ...        ...       ...            ...   ...    ...   \n",
      "8688     9276_01     Europa      False    A/98/P    55 Cancri e  41.0   True   \n",
      "8689     9278_01      Earth       True  G/1499/S  PSO J318.5-22  18.0  False   \n",
      "8690     9279_01      Earth      False  G/1500/S    TRAPPIST-1e  26.0  False   \n",
      "8691     9280_01     Europa      False   E/608/S    55 Cancri e  32.0  False   \n",
      "8692     9280_02     Europa      False   E/608/S    TRAPPIST-1e  44.0  False   \n",
      "\n",
      "      RoomService  FoodCourt  ShoppingMall  ...  Transported    Last_Name  \\\n",
      "0             0.0        0.0           0.0  ...        False    Ofracculy   \n",
      "1           109.0        9.0          25.0  ...         True        Vines   \n",
      "2            43.0     3576.0           0.0  ...        False       Susent   \n",
      "3             0.0     1283.0         371.0  ...        False       Susent   \n",
      "4           303.0       70.0         151.0  ...         True  Santantines   \n",
      "...           ...        ...           ...  ...          ...          ...   \n",
      "8688          0.0     6819.0           0.0  ...        False    Noxnuther   \n",
      "8689          0.0        0.0           0.0  ...        False    Mondalley   \n",
      "8690          0.0        0.0        1872.0  ...         True       Connon   \n",
      "8691          0.0     1049.0           0.0  ...        False    Hontichre   \n",
      "8692        126.0     4688.0           0.0  ...         True    Hontichre   \n",
      "\n",
      "     cabin_deck  cabin_num cabin_side missing_count  total_spending  \\\n",
      "0             B        0.0          P             0             0.0   \n",
      "1             F        0.0          S             0           736.0   \n",
      "2             A        0.0          S             0         10383.0   \n",
      "3             A        0.0          S             0          5176.0   \n",
      "4             F        1.0          S             0          1091.0   \n",
      "...         ...        ...        ...           ...             ...   \n",
      "8688          A       98.0          P             0          8536.0   \n",
      "8689          G     1499.0          S             0             0.0   \n",
      "8690          G     1500.0          S             0          1873.0   \n",
      "8691          E      608.0          S             0          4637.0   \n",
      "8692          E      608.0          S             0          4826.0   \n",
      "\n",
      "     money_spent  family_id  family_size  \n",
      "0          False     4399.0          1.0  \n",
      "1           True     6262.0          1.0  \n",
      "2           True     5929.0          2.0  \n",
      "3           True     5929.0          2.0  \n",
      "4           True     5360.0          1.0  \n",
      "...          ...        ...          ...  \n",
      "8688        True     4361.0          1.0  \n",
      "8689       False     4118.0          1.0  \n",
      "8690        True     1427.0          1.0  \n",
      "8691        True     2997.0          2.0  \n",
      "8692        True     2997.0          2.0  \n",
      "\n",
      "[8693 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Exclude rows where Last_Name is \"Nobody\" for family mapping\n",
    "df_family = df[df['Last_Name'] != 'Nobody'].copy()\n",
    "\n",
    "# Step 2: Create a unique family identifier based on Last_Name and Cabin\n",
    "df_family['family_id'] = df_family.groupby(['Last_Name', 'Cabin']).ngroup()\n",
    "\n",
    "# Step 3: Calculate family size\n",
    "family_size = df_family.groupby('family_id')['PassengerId'].transform('count')\n",
    "\n",
    "\n",
    "# Step 4: Map family_size and Is_family back to the original DataFrame\n",
    "df = df.merge(\n",
    "    df_family[['PassengerId', 'family_id']].assign(family_size=family_size),\n",
    "    on='PassengerId',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Step 5: Fill NaN values for family_size (for passengers with Last_Name \"Nobody\")\n",
    "df['family_size'] = df['family_size'].fillna(0).astype(int)\n",
    "\n",
    "# Step 6: Create the Is_family column\n",
    "df['Is_family'] = df['family_size'] > 1\n",
    "\n",
    "# Drop the temporary family_id column (optional)\n",
    "df = df.drop(columns=['family_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f8669d6b-b1e2-46e4-96f8-214e71467711",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Experiment (might be needed to remove) -> is female: most female first names end on a \"vocal\"! Otw 50/50\n",
    "def assign_gender(df):\n",
    "    \"\"\"\n",
    "    Extends the DataFrame by adding a 'Gender' column based on the first name.\n",
    "    - Assigns 'Female' if the first name ends in a vowel ('a', 'e', 'i', 'o', 'u').\n",
    "    - Assigns 'Male' otherwise.\n",
    "    - If the first name is missing, assigns gender randomly (50/50 chance).\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The input DataFrame containing a 'Name' column.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: The modified DataFrame with a new 'Gender' column.\n",
    "    \"\"\"\n",
    "    def determine_gender(name):\n",
    "        if pd.isna(name) or not isinstance(name, str) or name.strip() == \"\":\n",
    "            return np.random.choice([\"Male\", \"Female\"])  # 50/50 random assignment\n",
    "        \n",
    "        first_name = name.split()[0]  # Extract first name\n",
    "        return \"Female\" if first_name[-1].lower() in \"aeiou\" else \"Male\"\n",
    "\n",
    "    df['Gender'] = df['Name'].apply(determine_gender)  # Apply function to each row\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8cc860ef-0b8b-4614-ba4f-40092e2d63be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = assign_gender(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0a9a1d99-751e-4d75-8981-783b27b0d980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>...</th>\n",
       "      <th>Last_Name</th>\n",
       "      <th>cabin_deck</th>\n",
       "      <th>cabin_num</th>\n",
       "      <th>cabin_side</th>\n",
       "      <th>missing_count</th>\n",
       "      <th>total_spending</th>\n",
       "      <th>money_spent</th>\n",
       "      <th>family_size</th>\n",
       "      <th>Is_family</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>True</td>\n",
       "      <td>B/0/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Ofracculy</td>\n",
       "      <td>B</td>\n",
       "      <td>0.0</td>\n",
       "      <td>P</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Vines</td>\n",
       "      <td>F</td>\n",
       "      <td>0.0</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>736.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId HomePlanet  CryoSleep  Cabin  Destination   Age    VIP  \\\n",
       "0     0001_01     Europa       True  B/0/P  TRAPPIST-1e  39.0  False   \n",
       "1     0002_01      Earth      False  F/0/S  TRAPPIST-1e  24.0  False   \n",
       "\n",
       "   RoomService  FoodCourt  ShoppingMall  ...  Last_Name  cabin_deck cabin_num  \\\n",
       "0          0.0        0.0           0.0  ...  Ofracculy           B       0.0   \n",
       "1        109.0        9.0          25.0  ...      Vines           F       0.0   \n",
       "\n",
       "   cabin_side missing_count total_spending  money_spent family_size  \\\n",
       "0           P             0            0.0        False           1   \n",
       "1           S             0          736.0         True           1   \n",
       "\n",
       "   Is_family  Gender  \n",
       "0      False    Male  \n",
       "1      False  Female  \n",
       "\n",
       "[2 rows x 24 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0a8a9b32-f807-455a-8781-08922a489e86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'HomePlanet', 'CryoSleep', 'Cabin', 'Destination', 'Age',\n",
       "       'VIP', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck',\n",
       "       'Name', 'Transported', 'Last_Name', 'cabin_deck', 'cabin_num',\n",
       "       'cabin_side', 'missing_count', 'total_spending', 'money_spent',\n",
       "       'family_size', 'Is_family', 'Gender'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "bac25eb3-6e98-4135-af5c-05d609ec3d15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['TRAPPIST-1e', 'PSO J318.5-22', '55 Cancri e'], dtype=object)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Destination'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1e8c819b-5149-4dc8-aaba-0fb54aa6862a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId               0001_01\n",
       "HomePlanet                 Europa\n",
       "CryoSleep                    True\n",
       "Cabin                       B/0/P\n",
       "Destination           TRAPPIST-1e\n",
       "Age                          39.0\n",
       "VIP                         False\n",
       "RoomService                   0.0\n",
       "FoodCourt                     0.0\n",
       "ShoppingMall                  0.0\n",
       "Spa                           0.0\n",
       "VRDeck                        0.0\n",
       "Name              Maham Ofracculy\n",
       "Transported                 False\n",
       "Last_Name               Ofracculy\n",
       "cabin_deck                      B\n",
       "cabin_num                     0.0\n",
       "cabin_side                      P\n",
       "missing_count                   0\n",
       "total_spending                0.0\n",
       "money_spent                 False\n",
       "family_size                     1\n",
       "Is_family                   False\n",
       "Gender                       Male\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774d43d2-fb8c-4254-a586-d8f639e833ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Ensure cabin_num is numeric\n",
    "df['cabin_num'] = pd.to_numeric(df['cabin_num'], errors='coerce')\n",
    "\n",
    "# Step 1: Create new columns for even/odd and high/low cabin numbers\n",
    "df['cabin_even_odd'] = np.where(df['cabin_num'] % 2 == 0, 'Even', 'Odd')  # Even or Odd\n",
    "df['cabin_high_low'] = np.where(df['cabin_num'] > df['cabin_num'].median(), 'High', 'Low')  # High or Low\n",
    "\n",
    "# Step 2: Analyze the relationship per deck\n",
    "decks = sorted(df['cabin_deck'].dropna().unique())  # Get unique decks (A to T)\n",
    "\n",
    "for deck in decks:\n",
    "    print(f\"\\nAnalyzing Deck {deck}:\")\n",
    "    deck_df = df[df['cabin_deck'] == deck]  # Filter data for the current deck\n",
    "    \n",
    "    # Analyze even/odd vs cabin_side\n",
    "    contingency_table_even_odd = pd.crosstab(deck_df['cabin_side'], deck_df['cabin_even_odd'])\n",
    "    print(f\"\\nContingency Table for Deck {deck} (Even/Odd vs Cabin Side):\")\n",
    "    print(contingency_table_even_odd)\n",
    "    \n",
    "    chi2, p, dof, expected = chi2_contingency(contingency_table_even_odd)\n",
    "    print(f\"Chi-squared test for Even/Odd vs Cabin Side: p-value = {p:.4f}\")\n",
    "    \n",
    "    # Analyze high/low vs cabin_side\n",
    "    contingency_table_high_low = pd.crosstab(deck_df['cabin_side'], deck_df['cabin_high_low'])\n",
    "    print(f\"\\nContingency Table for Deck {deck} (High/Low vs Cabin Side):\")\n",
    "    print(contingency_table_high_low)\n",
    "    \n",
    "    chi2, p, dof, expected = chi2_contingency(contingency_table_high_low)\n",
    "    print(f\"Chi-squared test for High/Low vs Cabin Side: p-value = {p:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb0b00d-7377-4d8c-ac6b-c1e99c1a7fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Analyze Family and VIP Status\n",
    "# Create a family identifier based on Last_Name and Cabin\n",
    "df['family_id'] = df.groupby(['Last_Name', 'Cabin']).ngroup()\n",
    "\n",
    "# Group by family_id and check if VIP status is consistent within families\n",
    "family_vip = df.groupby('family_id')['VIP'].agg(['mean', 'size']).reset_index()\n",
    "family_vip['vip_consistent'] = family_vip['mean'].apply(lambda x: x == 0 or x == 1)\n",
    "\n",
    "# Count the number of families with consistent and inconsistent VIP status\n",
    "vip_consistency_summary = family_vip['vip_consistent'].value_counts()\n",
    "print(\"Family and VIP Status Consistency:\")\n",
    "print(vip_consistency_summary)\n",
    "\n",
    "# Step 2: Analyze CryoSleep and VIP Status\n",
    "# Count the number of passengers in CryoSleep with VIP status\n",
    "cryosleep_vip = df[df['CryoSleep'] == True]['VIP'].value_counts()\n",
    "print(\"\\nCryoSleep and VIP Status:\")\n",
    "print(cryosleep_vip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cbc00d-ac5e-48c1-ad94-2e462c9c437a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Step 1: Exclude rows where Last_Name is \"Nobody\" for family mapping\n",
    "df_family = df[df['Last_Name'] != 'Nobody'].copy()\n",
    "\n",
    "# Step 2: Create a unique family identifier based on Last_Name and Cabin\n",
    "df_family['family_id'] = df_family.groupby(['Last_Name', 'Cabin']).ngroup()\n",
    "\n",
    "# Step 3: Calculate family size\n",
    "family_size = df_family.groupby('family_id')['PassengerId'].transform('count')\n",
    "\n",
    "# Step 4: Map family_size and Is_family back to the original DataFrame\n",
    "df = df.merge(\n",
    "    df_family[['PassengerId', 'family_id']].assign(family_size=family_size),\n",
    "    on='PassengerId',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Step 5: Fill NaN values for family_size (for passengers with Last_Name \"Nobody\")\n",
    "df['family_size'] = df['family_size'].fillna(0).astype(int)\n",
    "\n",
    "# Step 6: Create the Is_family column\n",
    "df['Is_family'] = df['family_size'] > 1\n",
    "\n",
    "# Drop the temporary family_id column (optional)\n",
    "df = df.drop(columns=['family_id'])\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab31575a-bc31-4c77-a115-8b848b1ac51c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# 1. Side vs HomePlanet\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.countplot(data=df, x='cabin_side', hue='Is_family', palette='Set2')\n",
    "plt.title('CabinSide vs CabinDeck')\n",
    "plt.xlabel('HomePlanet')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(title='Cabin_Side', loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ddbf6b-6da2-47f4-9ec0-db73e0e2f6c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d43a382-f1cf-4e60-993f-ec8d359f86a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# 1. Side vs HomePlanet\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.countplot(data=df, x='cabin_deck', hue='cabin_side', palette='Set2')\n",
    "plt.title('CabinSide vs CabinDeck')\n",
    "plt.xlabel('HomePlanet')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(title='Cabin_Side', loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8175129-a93d-4bd0-9fec-a8232f8bbf8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18dcf696-95e0-4089-a0cc-3f92fc97b9a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d23ae6-81f3-46ab-990c-3f442c77c21f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cc6cd8-80d1-45f7-ac25-8cb5d8c52deb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# 1. Side vs HomePlanet\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.countplot(data=df, x='HomePlanet', hue='cabin_side', palette='Set2')\n",
    "plt.title('CabinSide vs HomePlanet')\n",
    "plt.xlabel('HomePlanet')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(title='Cabin_Side', loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76ef0e7-f080-42f9-926a-8a6a2056e803",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# 2. Side vs HomePlanet\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.countplot(data=df, x='HomePlanet', hue='cabin_deck', palette='Set2')\n",
    "plt.title('CabinDeck vs HomePlanet')\n",
    "plt.xlabel('HomePlanet')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(title='Cabin_Side', loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafcaf7a-bff6-4e02-addd-3f1bae11dd62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# 3. Side vs Destination\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.countplot(data=df, x='HomePlanet', hue='Destination', palette='Set2')\n",
    "plt.title('CabinSide vs Destination')\n",
    "plt.xlabel('Destination')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(title='Cabin_Side', loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b152f23-411a-4835-95f1-33bef34e63a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['HomePlanet'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99220c32-6deb-4447-bb98-581907084af9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# 4. Side vs Destination\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.countplot(data=df, x='Destination', hue='cabin_deck', palette='Set2')\n",
    "plt.title('CabinDeck vs Destination')\n",
    "plt.xlabel('Destination')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(title='Cabin_Deck', loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cb12de-cf6a-4596-bdf7-552dfbd711b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# 4. Side vs Destination\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.countplot(data=df, x='AgeGroup', hue='cabin_side', palette='Set2')\n",
    "plt.title('CabinDeck vs Destination')\n",
    "plt.xlabel('Destination')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(title='Cabin_Deck', loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d338c85-a7f7-4cf6-9118-d34737837f3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert cabin_num to numeric (handling errors by coercing invalid values to NaN)\n",
    "df['cabin_num'] = pd.to_numeric(df['cabin_num'], errors='coerce')\n",
    "\n",
    "# Detailed analysis of cabin_num\n",
    "print(\"Summary Statistics for cabin_num:\")\n",
    "print(df['cabin_num'].describe())\n",
    "\n",
    "print(\"\\nUnique Values in cabin_num:\")\n",
    "print(df['cabin_num'].unique())\n",
    "\n",
    "# Visualize the distribution of cabin_num\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df['cabin_num'].dropna(), bins=20, kde=True, color='blue')\n",
    "plt.title('Distribution of Cabin Numbers')\n",
    "plt.xlabel('Cabin Number')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193e2501-fcce-442c-ab51-7d21d22ed9e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccce028-0198-482a-987c-1d884c4a1961",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define the number of buckets and labels\n",
    "num_buckets = 5\n",
    "labels = ['low', 'medium-low', 'medium', 'medium-high', 'high']\n",
    "\n",
    "# Create bins based on the range of cabin_num\n",
    "min_num = df['cabin_num'].min()\n",
    "max_num = df['cabin_num'].max()\n",
    "bins = np.linspace(min_num, max_num, num_buckets + 1)\n",
    "\n",
    "# Bucketize cabin_num\n",
    "df['cabin_num_bucket'] = pd.cut(df['cabin_num'], bins=bins, labels=labels, include_lowest=True)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(df[['Cabin', 'cabin_num', 'cabin_num_bucket']])\n",
    "\n",
    "# Visualize the distribution of cabin_num_bucket\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=df, x='cabin_num_bucket', order=labels, palette='viridis')\n",
    "plt.title('Distribution of Cabin Number Buckets')\n",
    "plt.xlabel('Cabin Number Bucket')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44be4205-af28-4e75-86a9-76f3b6a7de16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a60e0b-e56e-4fc6-849d-60a5e0c149b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's plot CryoSleep against HomePlanet; Destination and Cabin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9777c296-f969-48de-9cbd-51d3c0549a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= df_filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba74de7-d489-42da-aeb9-944c4f447ede",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# 1. CryoSleep vs HomePlanet\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.countplot(data=df, x='HomePlanet', hue='CryoSleep', palette='Set2')\n",
    "plt.title('CryoSleep vs HomePlanet')\n",
    "plt.xlabel('HomePlanet')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(title='CryoSleep', loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801f673e-0531-4f99-b705-f800de717abf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 2. CryoSleep vs Destination\n",
    "# Handle NaN values in Destination by replacing them with \"Unknown\"\n",
    "df['Destination'].fillna('Unknown', inplace=True)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.countplot(data=df, x='Destination', hue='CryoSleep', palette='Set2')\n",
    "plt.title('CryoSleep vs Destination')\n",
    "plt.xlabel('Destination')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(title='CryoSleep', loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d243f598-97f1-44ed-9a29-8de878b1a97d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 3. CryoSleep vs Cabin (split into Deck, Num, Side)\n",
    "# Split the Cabin column into Deck, Num, and Side\n",
    "df[['Deck', 'Num', 'Side']] = df['Cabin'].str.split('/', expand=True)\n",
    "\n",
    "# Handle NaN values in Deck, Num, and Side by replacing them with \"Unknown\"\n",
    "df['Deck'].fillna('Unknown', inplace=True)\n",
    "df['Num'].fillna('Unknown', inplace=True)\n",
    "df['Side'].fillna('Unknown', inplace=True)\n",
    "\n",
    "# Plot CryoSleep vs Deck\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.countplot(data=df, x='Deck', hue='CryoSleep', palette='Set2')\n",
    "plt.title('CryoSleep vs Deck')\n",
    "plt.xlabel('Deck')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(title='CryoSleep', loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c386c0c5-4368-4d88-8c5c-c3b7874295d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3895b2a-c5d9-40a4-82f6-6e20a77197b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot CryoSleep vs Side\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.countplot(data=df, x='Side', hue='CryoSleep', palette='Set2')\n",
    "plt.title('CryoSleep vs Side')\n",
    "plt.xlabel('Side')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(title='CryoSleep', loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5101eb2-dfa8-4ecf-a65b-960f34d06fe7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 4. CryoSleep vs Age (bucketized into age groups of 10 years)\n",
    "# Create age groups\n",
    "df['AgeGroup'] = pd.cut(df['Age'], bins=range(0, 101, 10), right=False, labels=[f'{i}-{i+9}' for i in range(0, 100, 10)])\n",
    "\n",
    "# Convert AgeGroup to string type to allow adding \"Unknown\"\n",
    "df['AgeGroup'] = df['AgeGroup'].astype(str)\n",
    "\n",
    "# Handle NaN values in AgeGroup by replacing them with \"Unknown\"\n",
    "df['AgeGroup'].fillna('Unknown', inplace=True)\n",
    "\n",
    "# Plot CryoSleep vs AgeGroup\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=df, x='AgeGroup', hue='CryoSleep', palette='Set2', order=sorted(df['AgeGroup'].unique()))\n",
    "plt.title('CryoSleep vs Age Group')\n",
    "plt.xlabel('Age Group')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(title='CryoSleep', loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf3df6b-999b-40c6-8a43-eca61eb6af79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df_filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47663caf-0e75-4d6f-8dd2-501b1d309454",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Let's investigate VIP\n",
    "# Create binary indicators for spending (1 if spent money, 0 if not)\n",
    "spending_columns = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "for col in spending_columns:\n",
    "    df[f'{col}_spent'] = df[col].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "# Melt the DataFrame for easier plotting\n",
    "melted_df = df.melt(id_vars=['VIP'], value_vars=[f'{col}_spent' for col in spending_columns],\n",
    "                    var_name='SpendingCategory', value_name='SpentMoney')\n",
    "\n",
    "# Replace SpendingCategory labels for better readability\n",
    "melted_df['SpendingCategory'] = melted_df['SpendingCategory'].str.replace('_spent', '')\n",
    "\n",
    "# Plot the data\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(data=melted_df, x='SpendingCategory', y='SpentMoney', hue='VIP', ci=None, palette='Set2')\n",
    "plt.title('Proportion of Passengers Who Spent Money by VIP Status')\n",
    "plt.xlabel('Spending Category')\n",
    "plt.ylabel('Proportion Who Spent Money')\n",
    "plt.legend(title='VIP Status', loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b894b6a-05a8-425a-b46d-ec648f7b0c11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create binary indicators for spending (1 if spent money, 0 if not)\n",
    "spending_columns = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "for col in spending_columns:\n",
    "    df[f'{col}_spent'] = df[col].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "# Melt the DataFrame for easier plotting\n",
    "melted_df = df.melt(id_vars=['VIP'], value_vars=[f'{col}_spent' for col in spending_columns],\n",
    "                    var_name='SpendingCategory', value_name='SpentMoney')\n",
    "\n",
    "# Replace SpendingCategory labels for better readability\n",
    "melted_df['SpendingCategory'] = melted_df['SpendingCategory'].str.replace('_spent', '')\n",
    "\n",
    "# Calculate the proportion of VIP statuses for each spending category\n",
    "vip_proportions = melted_df.groupby(['SpendingCategory', 'SpentMoney', 'VIP']).size().unstack(fill_value=0)\n",
    "vip_proportions = vip_proportions.div(vip_proportions.sum(axis=1), axis=0).reset_index()\n",
    "\n",
    "# Filter for rows where money was spent (SpentMoney == 1)\n",
    "vip_proportions = vip_proportions[vip_proportions['SpentMoney'] == 1]\n",
    "\n",
    "# Melt the DataFrame again for plotting\n",
    "vip_proportions_melted = vip_proportions.melt(id_vars=['SpendingCategory', 'SpentMoney'],\n",
    "                                              value_vars=[True, False],\n",
    "                                              var_name='VIP', value_name='Proportion')\n",
    "\n",
    "# Plot the data\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(data=vip_proportions_melted, x='SpendingCategory', y='Proportion', hue='VIP', palette='Set2')\n",
    "plt.title('Proportion of VIP Status for Passengers Who Spent Money')\n",
    "plt.xlabel('Spending Category')\n",
    "plt.ylabel('Proportion of VIP Status')\n",
    "plt.legend(title='VIP Status', loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eeba97f-8c35-4885-991a-94b9a3a22c11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Melt the DataFrame for easier plotting\n",
    "melted_df = df.melt(id_vars=['VIP'], value_vars=['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck'],\n",
    "                    var_name='SpendingCategory', value_name='AmountSpent')\n",
    "\n",
    "# Group by VIP status and SpendingCategory, then calculate median and standard deviation\n",
    "grouped_df = melted_df.groupby(['VIP', 'SpendingCategory'])['AmountSpent'].agg(['median', 'std']).reset_index()\n",
    "\n",
    "# Plot the data\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(data=grouped_df, x='SpendingCategory', y='median', hue='VIP', palette='Set2', ci='sd')\n",
    "plt.title('Median Amount Spent by VIP Status (with Standard Deviation Error Bars)')\n",
    "plt.xlabel('Spending Category')\n",
    "plt.ylabel('Median Amount Spent')\n",
    "plt.legend(title='VIP Status', loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2983fa61-9472-436d-8613-2a6c8086ec51",
   "metadata": {},
   "outputs": [],
   "source": [
    "cryosleep_spending = df.groupby('CryoSleep')[['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']].sum()\n",
    "\n",
    "# Display the results\n",
    "print(\"Total Amount Spent by CryoSleep Status:\")\n",
    "print(cryosleep_spending)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c1a725-dfbe-42c8-b563-c5f82474b658",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Hence people in CrySleep don't spend money!!!\n",
    "service_columns = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "\n",
    "df.loc[df['CryoSleep'] == True, service_columns] = df.loc[df['CryoSleep'] == True, service_columns].fillna(0)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(\"DataFrame after imputing missing values for CryoSleep passengers:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011ed57a-0d6e-4ace-86d4-870c8ec4e50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_rows = df[df.isna().any(axis=1)]\n",
    "nan_counts = df.isna().sum()\n",
    "\n",
    "print(nan_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98d9f52-e6a8-40a4-bcca-5afe32450e8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5900316b-995e-40a1-ba3a-94bc2656c007",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#investigate cabins? Is there a logic per deck? \n",
    "# Check for odd/even numbering by Side\n",
    "df['CabinParity'] = df['cabin_num'] % 2\n",
    "df['InferredSide'] = np.where(df['CabinParity'] == 0, 'S', 'P')  # Example logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ea4f0d-82ee-47b6-b24a-413400186873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the service columns\n",
    "service_columns = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "\n",
    "# Group by Deck and calculate the average spending for each service\n",
    "average_spending_by_deck = df.groupby('cabin_deck')[service_columns].median()\n",
    "\n",
    "# Display the results\n",
    "print(\"Median Spending by Deck Level:\")\n",
    "print(average_spending_by_deck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96d1c99-e3e1-4bb2-8a66-832eac855dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a cross-tabulation of cabin_level vs cabin_side\n",
    "cross_tab = pd.crosstab(df['cabin_deck'], df['cabin_side'])\n",
    "\n",
    "# Calculate the S/P ratio for each cabin level\n",
    "cross_tab['S/P Ratio'] = cross_tab['S'] / cross_tab['P']\n",
    "\n",
    "# Display the results\n",
    "print(\"Cross-Tabulation of Cabin Level vs Cabin Side with S/P Ratio:\")\n",
    "print(cross_tab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48c236c-e03b-4b50-8a6f-fcb5f0b67d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a cross-tabulation of cabin_level vs cabin_side\n",
    "cross_tab = pd.crosstab(df['cabin_deck'], df['VIP'])\n",
    "# Display the results\n",
    "print(cross_tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331088f2-5be9-4972-b290-b900a044e676",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d6dc30-0fa5-48c5-a0d4-1160d91798e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5cc04c-25b4-41d2-872d-4daf2b31b555",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6ba2fd-4c45-49d9-8bfb-83b1a884751a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90488b1-8d20-453c-8193-664718111408",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
